from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import pickle # Used for loading your saved model and preprocessors

app = Flask(__name__)
CORS(app) # Enable CORS for frontend connection

# --- STEP 1: LOAD MODEL AND PREPROCESSORS ---
# Uncomment and update file paths to load your trained model and pipeline components.
# try:
#     with open('your_ml_model.pkl', 'rb') as f:
#         model = pickle.load(f)
#     with open('your_preprocessor.pkl', 'rb') as f:
#         preprocessor = pickle.load(f)
# except FileNotFoundError:
#     model = None
#     preprocessor = None
#     print("WARNING: Model or preprocessor files not found. Using dummy data.")

# --- DUMMY DATA FOR DEMO (REPLACE WITH REAL LOGIC) ---
def mock_ml_prediction(df):
    """Simulates prediction and structured data generation."""
    
    # 1. Simulate Prediction Probability
    is_month_to_month = df['Contract'].iloc[0] == 'Month-to-month'
    is_fiber = df['InternetService'].iloc[0] == 'Fiber optic'
    tenure_low = df['tenure'].iloc[0] < 12
    monthly_charge = df['MonthlyCharges'].iloc[0]

    prob = 0.10
    if is_month_to_month: prob += 0.35
    if is_fiber: prob += 0.25
    if tenure_low: prob += 0.15
    prob += (monthly_charge / 120.0) * 0.05
    
    probability = np.clip(prob, 0.05, 0.95)
    prediction = 1 if probability > 0.5 else 0
    
    # 2. Simulate Feature Contribution Table Data
    # In a real app, this would be generated by SHAP/LIME or feature importance.
    contribution_data = [
        {"feature": "Contract Type", "score": 0.60 if is_month_to_month else -0.40, "explanation": "Short-term contracts are the single largest risk factor."},
        {"feature": "Internet Service", "score": 0.30 if is_fiber else -0.15, "explanation": "Fiber customers have higher switching volatility."},
        {"feature": "Tenure", "score": 0.45 if tenure_low else -0.20, "explanation": f"New users (Tenure: {df['tenure'].iloc[0]} months) are highly likely to switch."},
        {"feature": "Online Security", "score": -0.05, "explanation": "Lack of security add-ons indicates a basic, easily replaceable package."},
        {"feature": "MonthlyCharges", "score": monthly_charge / 100, "explanation": f"High recurring cost (${monthly_charge}) is driving dissatisfaction."},
    ]
    
    # 3. Simulate Radar Chart Data (Normalized 0-1)
    radar_data = {
        'tenure': (1 - df['tenure'].iloc[0] / 72),
        'charges': (df['MonthlyCharges'].iloc[0] / 120),
        'total_charges': (1 - df['TotalCharges'].iloc[0] / 8600),
        'service_usage': (0.8 if is_fiber else 0.4),
        'contract_type': (0.9 if is_month_to_month else 0.1),
        'support_availability': (0.7 if df['TechSupport'].iloc[0] == 'No' else 0.3)
    }

    return {
        "prediction": prediction,
        "probability": float(probability),
        "feature_contributions": contribution_data,
        "radar_scores": radar_data
    }
# --- END DUMMY DATA ---


@app.route('/predict', methods=['POST'])
def predict():
    # Frontend sends raw JSON data (15 features)
    raw_input_data = request.json 
    
    # --- STEP 2: CONVERT TO DATAFRAME ---
    # Convert the single JSON object into a DataFrame with one row
    try:
        input_df = pd.DataFrame([raw_input_data])
    except Exception as e:
        return jsonify({"error": "Invalid data format for DataFrame conversion."}), 400


    # --- STEP 3: PREPROCESS THE DATAFRAME ---
    # *** THIS IS THE CRITICAL SECTION YOU MUST COMPLETE ***
    # You need to load your saved preprocessor (e.g., ColumnTransformer)
    # and apply all the transformations (OHE, scaling) defined in your notebook.
    
    # Example (Replace with your specific preprocessing steps):
    # if preprocessor:
    #     processed_data = preprocessor.transform(input_df)
    #     # Convert back to DataFrame with feature names if necessary for SHAP/LIME
    # else:
    #     # For this demo, we just use the raw DataFrame inside the mock function
    #     processed_data = input_df 

    # --- STEP 4: GENERATE PREDICTION AND STRUCTURED DATA ---
    
    # if model:
    #     # Call your actual model here on the processed_data
    #     # prediction = model.predict(processed_data)[0]
    #     # probability = model.predict_proba(processed_data)[:, 1][0]
    #     #
    #     # *** THEN, GENERATE YOUR FEATURE_CONTRIBUTIONS AND RADAR_SCORES ***
    #     # This part is complex. You can use SHAP on your model output here.
    #     # structured_output = generate_structured_insights(processed_data, prediction, probability)
    #     
    #     # return jsonify(structured_output)
    # else:
    
    # --- Using Mock Data for Demonstration ---
    structured_output = mock_ml_prediction(input_df)
    return jsonify(structured_output)


if __name__ == '__main__':
    # Run the Flask app on default port 5000
    app.run(debug=True)